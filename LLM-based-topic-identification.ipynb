{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1001 reviews\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "project_id = 'ingka-tugc-infra-prod'\n",
    "dataset_id = 'eu_ai_content'\n",
    "table_id = 'reviews'\n",
    "\n",
    "table_ref = f'{project_id}.{dataset_id}.{table_id}'\n",
    "\n",
    "# First 5 articles with under 1k reviews\n",
    "\n",
    "articles_1000reviews = ['00577935', '30393063', '40577943', '50361792', '20393073']\n",
    "\n",
    "article_id = articles_1000reviews[1]\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT concat(title, '. ', text) as review_text\n",
    "    FROM {table_ref}\n",
    "    WHERE franchise='set-11' AND content_lang_code = 'en' AND art_id = '{article_id}'\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "\n",
    "reviews = [row['review_text'] for row in query_job]\n",
    "\n",
    "print(f\"Processing {len(reviews)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from utils.getSecret import get_secret\n",
    "\n",
    "project = \"923326131319\"\n",
    "secret  = \"derai-azure\"\n",
    "api_key = get_secret(project, secret)\n",
    "\n",
    "llm_client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=\"https://derai-vision.openai.azure.com/\",\n",
    ")\n",
    "\n",
    "model = \"gpt-4o\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(reviews):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an helpful customer reviews expert that identifies the main topics discussed in a group of reviews.\\n\"\n",
    "                \"Use singular words unless a plural form is necessary.\\n\"                \n",
    "                \"Use only one word. 2 or 3 words can be used only when they are part of a composite word and are better to represent the idea of the topic (e.g.: Ease of use).\\n\"\n",
    "                \"If you identify a verb as a topic, use the noun version (e.g.: use 'Order' instead of 'Ordering').\\n\"\n",
    "                \"Generalize the topic word; for example, if you encounter 'Saleswoman' or 'Salesman', abstract it to 'Staff'.\\n\"\n",
    "                \"Provide the output as a comma-separated list of topics with the first letter capitalized.\\n\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Read the following reviews and generate a maximum of 8 topics that are mentioned in the reviews.\\n\"\n",
    "                \"For each topic that you generate, indicate which reviews mention implicitly or explicitly that topic.\\n\"\n",
    "                \"ONLY return topics that are mentioned more than once, don't consider topics mentioned only in a couple of reviews.\\n\"\n",
    "                \"The topic names should be broad and general, for example Quality, Price, etc.\\n\"\n",
    "                \"The topics could be either nouns that refers to a certain characteristic of the product or spefic features or parts of the product (screws, cookware, etc.)\\n\"\n",
    "                \"First return all the topics that you identify as a comma-separated list, then for each of them return a few reviews that mention it.\\n\"\n",
    "                f\"Reviews: {', '.join(reviews)}\\n\"\n",
    "                \"Topics:\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = ' '\n",
    "    \n",
    "    # Generate the topic word using the language model\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.4,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    # Extract and return the topic word\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lid, Seal, Quality, Price, Fit, Breakage, Smell, Cleanliness\n",
      "\n",
      "1. Lid\n",
      "- The only lid in stock!  . I prefer the bamboo lids but this is all they had in stock. Tabs can break off (check them before you buy) and I avoid plastic food storage.\n",
      "- Not holding the vacuum seal. I have been using similar round products for years and was very excited to find these to fit my rectangular and square IKEA glass containers. However, they do not hold the seal and are pretty useless. I am glad I only bought one of each to test.\n",
      "- Lid alternative. Good alternative to the lids that crack after a few years, Love it.. Love it.\n",
      "- Glass container with lid. This can be your lunch box and also container for putting into your microwave. It's only $2.\n",
      "- Functional. We are buying this as a replacement. The previous lid is has a hinge that is slowly breaking. We think part of the problem comes from putting it through the dishwasher, but maybe not.\n",
      "- Clip on lids easy to. Clip on lids easy to use\n",
      "- Kids don’t fit well. I prefer the glass containers to these plastic ones but the glass ones are nowhere to be found now. The kids do not fit the containers well and it is a struggle to get them to close. Try not to break your nails!!\n",
      "- Works great tight fit to. Works great tight fit to keep air out\n",
      "- Lid. Good deal. easy to use. Easy to clean. Makes a good seal.\n",
      "- The Lids seal wonderfully.\n",
      "- Great lid, very versatile.. Great lid, very versatile.\n",
      "- Is this goodbye?. We have several of the containers this lid goes with, but they were all gone and these lids were half off. It’s sad if they’re discontinued.\n",
      "- Necessary for the container. Necessary for the container\n",
      "- Great Locking Seal. Purchased this lid to fit the glass food container, the only thing is that I have a little problem trying to seal the lock as the sides were hard to lock. But once done it had a great locking seal with no spills and a solid grip.\n",
      "- Keeps a great seal. Keeps a great seal\n",
      "- Broke first use!. Didn't last one day. Side clips broke when putting it on the glass container :(\n",
      "- Tough container. Strong and tough\n",
      "- Amazing!!. Perfect for work! Just what I needed.\n",
      "- perfect in every way. the seal it provides is impressive. so far it doesn't stain even microwaving ravioli in a heavy tomato sauce. it clean easily. I have peace of mind knowing there's no plastic dripping back into my food when i microwave. the handle makes it easy to handle long microwave cycles without burning yourself and it's very rigid so it doesn't flop around or in my food. i went back and bought the smaller circular lid just because of this one\n",
      "- So excited to have a SQUARE lid. Works great.\n",
      "- Lids for glass storage. An essential part of the storage, works very well and they are well made.\n",
      "- Great quality. Great quality,\n",
      "- Have bought several as so useful\n",
      "- Great product!. Great product!\n",
      "- Designed to fail. Designed to fail\n",
      "- Nice to purchase separately. Nice to purchase separately\n",
      "- Very good product, well made. Very good product, well made and easy to use.\n",
      "- Hard to snap closed. These don’t seem to be as air tight as they appear. They can be tricky to snap shut. But living in Florida I need to use them to keep moisture out.\n",
      "- Multiple Uses. Excellent product with several uses.\n",
      "- prictical. prictical\n",
      "- Very good. Very good\n",
      "- Really cool lid… tho$$$$. I like this lid a lot. It has a wonderful suction that works perfectly with the correctly sized glass container. It doesn’t translate to other size containers though it can be used in a pinch. I think that the price point is a little too high. I won’t buy another, but I really like the one I got!\n",
      "- Perfect for the house.. Perfect for the house.\n",
      "- The Perfect Tray for every Room . It has such a nice texture and look so beautiful with a set of wine glasses or white porcelain bowls. It also looks great in an office setting on a shelf!\n",
      "- Best lid ever. This is a lid which is the best because other plastic or rubber lids can disintegrate after sometime. It is light, easy to use & clean. IKEA, pls keep this item in the store forever!\n",
      "- Easy snap lid. Sturdy lid.\n",
      "- Clip Lid. I love that this lid can attach to both the plastic tupperware and glass pyrex dishes\n",
      "- Easy to use, seals really well. Handy to use & sustainable vs using glad wrap all the time. Seals really well against glass.\n",
      "- Bathroom, laundry or kitchen spray. Bathroom, laundry or kitchen spray bottle\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "answer = get_topics(reviews)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lid', 'Seal', 'Quality', 'Price', 'Fit', 'Breakage', 'Smell', 'Cleanliness']\n"
     ]
    }
   ],
   "source": [
    "topics = answer.split('\\n')[0].split(', ')\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davide.zanutto1/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted topics: 0\n",
      "Unique topics: ['Lid', 'Seal', 'Quality', 'Price', 'Fit', 'Breakage', 'Smell', 'Cleanliness']\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Define the embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Encode the topics\n",
    "topic_embeddings = model.encode(topics, convert_to_numpy=True)\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(topic_embeddings)\n",
    "\n",
    "# Set a similarity threshold\n",
    "similarity_threshold = 0.75\n",
    "\n",
    "# Identify and remove similar topics\n",
    "unique_topics = topics.copy()\n",
    "for i in range(len(topics)):\n",
    "    for j in range(i + 1, len(topics)):\n",
    "        if similarity_matrix[i, j] > similarity_threshold:\n",
    "            if topics[j] in unique_topics:\n",
    "                unique_topics.remove(topics[j])\n",
    "                \n",
    "deleted_topics_count = len(topics) - len(unique_topics)\n",
    "print(\"Number of deleted topics:\", deleted_topics_count)\n",
    "print(\"Unique topics:\", unique_topics)\n",
    "topics = unique_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Identification Evaluation - Are those 8 topics good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Lid\":5, \"Seal\":5, \"Quality\":5, \"Price\":4, \"Fit\":4, \"Breakage\":4, \"Smell\":3, \"Cleanliness\":4]\n",
      "\n",
      "| Topic       | Rating | Justification                                                                                                                                                                 |\n",
      "|-------------|--------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
      "| Lid         | 5      | The majority of reviews discuss the lid’s functionality, ease of use, and design, indicating it is a central aspect of the product.                                           |\n",
      "| Seal        | 5      | Numerous comments focus on the airtight and leakproof qualities of the seal, highlighting its importance and effectiveness.                                                    |\n",
      "| Quality     | 5      | Reviews frequently mention both positive and negative aspects of quality, including durability and materials used, underscoring its high relevance.                           |\n",
      "| Price       | 4      | Many reviews comment on the affordability and value for money, though it is slightly less emphasized than the top topics.                                                     |\n",
      "| Fit         | 4      | Several reviews address how well the lids fit the containers, indicating it is an important but secondary concern.                                                              |\n",
      "| Breakage    | 4      | A significant number of reviews mention lids or components breaking, stressing the importance of durability.                                                                    |\n",
      "| Smell       | 3      | A few reviews note unpleasant smells from certain lids, making it relevant but not as frequently discussed as other topics.                                                    |\n",
      "| Cleanliness | 4      | Many reviews mention ease of cleaning, mold issues, and maintenance, showing that cleanliness is a relevant factor for users.                                                 |\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "prompt = f\"\"\"You are an AI review analyst. Your task is to analyze a collection of reviews and assess the following topics: \"{topics}\" \n",
    "            Go through all of the reviews and check that each topic is mentioned either explicitly or implicitly. \n",
    "            Once you read all the reviews, provide a rating for each topic (from 0 to 5) considering the relevance of the topic to the reviews.\n",
    "            If a topic is not mentioned in the reviews, you should rate it as 0. If it is mentioned in a lot of reviews, you should rate it as 5.\n",
    "            Reviews: \"{', '.join(reviews)}\" \n",
    "            Answer first with an array of scoring of the type 'Topic':'Rating' (e.g.: Quality: 5, Price: 5, ...) and after that, on a new line, \n",
    "            with a table containing the topics, their ratings and a brief justification on why that score has been assigned. \n",
    "            Remember that the score only indicated how much a topic is relevant for that group of reviews. \n",
    "            Do not add any additional text to the answer.\"\"\"\n",
    "\n",
    "ai_client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=\"https://derai-vision.openai.azure.com/\",\n",
    ")\n",
    "result = ai_client.chat.completions.create(\n",
    "    model=\"o1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic assignment - Labeling each review with 0 to N topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 3-shot learning - GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    azure_endpoint=\"https://derai-vision.openai.azure.com/\",\n",
    ")\n",
    "\n",
    "model = \"gpt-4o\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews_labels_3shots(review, topics):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a helpful customer reviews expert that identifies the main topics in a review.\\n\"\n",
    "                \"Provide the output as a comma-separated list of topics. The first letter of the topics should always be capitalized.\\n\"\n",
    "            ),\n",
    "        },\n",
    "        # Example 1\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Read the following review and associate the topics mentioned implicitly or explicitly in the review.\\n\"\n",
    "                \"Only answer with the topics that are mentioned in the review. Example: ['price', 'quality']. \\n\"\n",
    "                \"If you cannot identify any topics, just return '[]' \\n\"\n",
    "                \"Review: 'The product arrived quickly, and the packaging was great. However, the price is too high.'\\n\"\n",
    "                \"Topics: ['Delivery', 'Packaging', 'Price', 'Quality']. DO NOT write any topics outside of this list. \\n\"\n",
    "                \"Topics mentioned within the review:\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"['Delivery', 'Packaging', 'Price']\",\n",
    "        },\n",
    "        # Example 2\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Read the following review and associate the topics mentioned implicitly or explicitly in the review.\\n\"\n",
    "                \"Only answer with the topics that are mentioned in the review. Example: ['price', 'quality']. \\n\"\n",
    "                \"If you cannot identify any topics, just return '[]' \\n\"\n",
    "                \"Review: 'I love how comfortable these shoes are! They fit perfectly, and the material feels premium. Good price.'\\n\"\n",
    "                \"Topics: ['Comfort', 'Fit', 'Material', 'Design', 'Value']. DO NOT write any topics outside of this list.\\n\"\n",
    "                \"Topics mentioned within the review:\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"['Comfort', 'Fit', 'Material', 'Value']\",\n",
    "        },\n",
    "        # Example 3\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Read the following review and associate the topics mentioned implicitly or explicitly in the review.\\n\"\n",
    "                \"Only answer with the topics that are mentioned in the review. Example: ['price', 'quality']. \\n\"\n",
    "                \"If you cannot identify any topics, just return '[]' \\n\"\n",
    "                \"Review: 'The app crashes frequently and is very slow. It needs major improvements.'\\n\"\n",
    "                \"Topics: ['Performance', 'Usability', 'Design']. DO NOT write any topics outside of this list. \\n\"\n",
    "                \"Topics mentioned within the review:\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"['Performance', 'Usability']\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Read the following review and associate the topics mentioned implicitly or explicitly in the review.\\n\"\n",
    "                \"Only answer with the topics that are mentioned in the review. Example: ['Price', 'Quality']. \\n\"\n",
    "                \"If you cannot identify any topics, just return '[]' \\n\"\n",
    "                f\"Review: '{review}' \\n\"\n",
    "                f\"Topics: {topics}. DO NOT write any topics outside of this list. \\n\"\n",
    "                f\"Topics mentioned within the review:\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = ' '\n",
    "    model = \"gpt-4o\" \n",
    "    # Generate the topic word using the language model\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=30,\n",
    "        temperature=0.4,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    # Extract and return the topic word\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lid', 'Seal', 'Quality', 'Price', 'Fit', 'Breakage', 'Smell', 'Cleanliness']\n"
     ]
    }
   ],
   "source": [
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Content filter triggered for review: Quality lid . Nice tight snappy little fellow. . Skipping.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "results = []\n",
    "for review in reviews:\n",
    "    try:\n",
    "        result = get_reviews_labels_3shots(review, topics)\n",
    "        result = [topic for topic in eval(result) if topic in topics]\n",
    "        results.append([review, result])\n",
    "    except Exception as e:\n",
    "        # Check for content filter issues\n",
    "        if \"content_filter\" in str(e) or \"ResponsibleAIPolicyViolation\" in str(e):\n",
    "            logging.error(f\"Content filter triggered for review: {review} - Skipping.\")\n",
    "            results.append([review, []])  # Add review with empty topics\n",
    "        else:\n",
    "            # Log other exceptions\n",
    "            logging.error(f\"Error processing review: {review} - {e}\")\n",
    "            results.append([review, []])  # Add review with empty topics\n",
    "\n",
    "# Transform results into a DataFrame\n",
    "df = pd.DataFrame(results, columns=[\"review\", \"topics\"])\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(f'csv/LLM3shots_{article_id}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit_csv = f'LLM3shots_{article_id}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import json\\nimport pandas as pd\\nimport ast\\n\\ndef load_ground_truth(csv_file):\\n    df = pd.read_csv(csv_file)\\n    # Convert the topics column (a string) into an actual list.\\n    df[\\'topics\\'] = df[\\'topics\\'].apply(ast.literal_eval)\\n    return df\\n\\ndef load_predictions(json_file):\\n    with open(json_file, \"r\", encoding=\"utf-8\") as f:\\n        data = json.load(f)\\n\\n    # Filter out entries that do not contain a \\'review\\' key\\n    predictions = [entry for entry in data if \"review\" in entry]\\n\\n    return predictions  # List of reviews with topics\\n\\ndef compute_precision_recall_f1(gt_topics, pred_topics):\\n    # True positives: the intersection of predicted and ground truth topics.\\n    true_positives = len(gt_topics & pred_topics)\\n    \\n    precision = true_positives / len(pred_topics) if pred_topics else 0.0\\n    recall = true_positives / len(gt_topics) if gt_topics else 0.0\\n    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\\n    \\n    return precision, recall, f1\\n\\ndef safe_literal_eval(val):\\n    try:\\n        if isinstance(val, str):\\n            return ast.literal_eval(val)\\n        return val  # If it\\'s already a list, return as is.\\n    except (ValueError, SyntaxError):\\n        print(f\"Warning: Could not parse topics: {val}\")\\n        return []  # Return an empty list if parsing fails.\\n\\n# Load the CSV file\\ngt_df = pd.read_csv(\"csv/ground_truth.csv\")\\n\\n# Apply the safe conversion\\ngt_df[\\'topics\\'] = gt_df[\\'topics\\'].apply(safe_literal_eval)\\n\\n\\npredictions = load_predictions(json_name)\\n\\n# List the models that we want to evaluate (must match keys in the JSON)\\nmodels = [\\n    \"deberta_v3_topics\",\\n    \"nli_deberta_v3_topics\",\\n    \"bart_large_mnli_topics\",\\n    \"embedding_similarity_topics\",\\n    \"word_embedding_similarity_topics\",\\n    \"LLM_topics\",\\n    \"LLM_3shots_topics\"\\n]\\n\\n# Initialize an accumulator for metrics per model.\\nmetrics = {model: {\"precision\": [], \"recall\": [], \"f1\": []} for model in models}\\n\\n# Check that the number of reviews is the same in both files.\\nif len(gt_df) != len(predictions):\\n    print(\"len(gt_df),\", len(gt_df))\\n    print(\"len(predictions),\", len(predictions))\\n    raise ValueError(\"The number of reviews in the CSV and JSON files do not match!\")\\n\\n# Iterate over the reviews (assumed aligned by index)\\nfor idx, pred_entry in enumerate(predictions):\\n    # For consistency, we compare topics in lowercase with whitespace stripped.\\n    gt_topics = {topic.lower().strip() for topic in gt_df.iloc[idx][\"topics\"]}\\n    \\n    for model in models:\\n        # In the JSON predictions, if a model has produced topics,\\n        # we take the keys (ignoring the scores) as the predicted topics.\\n        pred_model_dict = pred_entry.get(model, {})\\n        pred_topics = {topic.lower().strip() for topic in pred_model_dict.keys()}\\n        \\n        precision, recall, f1 = compute_precision_recall_f1(gt_topics, pred_topics)\\n        \\n        metrics[model][\"precision\"].append(precision)\\n        metrics[model][\"recall\"].append(recall)\\n        metrics[model][\"f1\"].append(f1)\\n\\n# Compute the average scores for each model and print them\\nfor model in models:\\n    avg_precision = sum(metrics[model][\"precision\"]) / len(metrics[model][\"precision\"])\\n    avg_recall = sum(metrics[model][\"recall\"]) / len(metrics[model][\"recall\"])\\n    avg_f1 = sum(metrics[model][\"f1\"]) / len(metrics[model][\"f1\"])\\n    print(f\"Model: {model}\")\\n    print(f\"  Precision: {avg_precision:.3f}\")\\n    print(f\"  Recall:    {avg_recall:.3f}\")\\n    print(f\"  F1 Score:  {avg_f1:.3f}\")\\n    print(\"-\" * 30)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def load_ground_truth(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Convert the topics column (a string) into an actual list.\n",
    "    df['topics'] = df['topics'].apply(ast.literal_eval)\n",
    "    return df\n",
    "\n",
    "def load_predictions(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Filter out entries that do not contain a 'review' key\n",
    "    predictions = [entry for entry in data if \"review\" in entry]\n",
    "\n",
    "    return predictions  # List of reviews with topics\n",
    "\n",
    "def compute_precision_recall_f1(gt_topics, pred_topics):\n",
    "    # True positives: the intersection of predicted and ground truth topics.\n",
    "    true_positives = len(gt_topics & pred_topics)\n",
    "    \n",
    "    precision = true_positives / len(pred_topics) if pred_topics else 0.0\n",
    "    recall = true_positives / len(gt_topics) if gt_topics else 0.0\n",
    "    f1 = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        if isinstance(val, str):\n",
    "            return ast.literal_eval(val)\n",
    "        return val  # If it's already a list, return as is.\n",
    "    except (ValueError, SyntaxError):\n",
    "        print(f\"Warning: Could not parse topics: {val}\")\n",
    "        return []  # Return an empty list if parsing fails.\n",
    "\n",
    "# Load the CSV file\n",
    "gt_df = pd.read_csv(\"csv/ground_truth.csv\")\n",
    "\n",
    "# Apply the safe conversion\n",
    "gt_df['topics'] = gt_df['topics'].apply(safe_literal_eval)\n",
    "\n",
    "\n",
    "predictions = load_predictions(json_name)\n",
    "\n",
    "# List the models that we want to evaluate (must match keys in the JSON)\n",
    "models = [\n",
    "    \"deberta_v3_topics\",\n",
    "    \"nli_deberta_v3_topics\",\n",
    "    \"bart_large_mnli_topics\",\n",
    "    \"embedding_similarity_topics\",\n",
    "    \"word_embedding_similarity_topics\",\n",
    "    \"LLM_topics\",\n",
    "    \"LLM_3shots_topics\"\n",
    "]\n",
    "\n",
    "# Initialize an accumulator for metrics per model.\n",
    "metrics = {model: {\"precision\": [], \"recall\": [], \"f1\": []} for model in models}\n",
    "\n",
    "# Check that the number of reviews is the same in both files.\n",
    "if len(gt_df) != len(predictions):\n",
    "    print(\"len(gt_df),\", len(gt_df))\n",
    "    print(\"len(predictions),\", len(predictions))\n",
    "    raise ValueError(\"The number of reviews in the CSV and JSON files do not match!\")\n",
    "\n",
    "# Iterate over the reviews (assumed aligned by index)\n",
    "for idx, pred_entry in enumerate(predictions):\n",
    "    # For consistency, we compare topics in lowercase with whitespace stripped.\n",
    "    gt_topics = {topic.lower().strip() for topic in gt_df.iloc[idx][\"topics\"]}\n",
    "    \n",
    "    for model in models:\n",
    "        # In the JSON predictions, if a model has produced topics,\n",
    "        # we take the keys (ignoring the scores) as the predicted topics.\n",
    "        pred_model_dict = pred_entry.get(model, {})\n",
    "        pred_topics = {topic.lower().strip() for topic in pred_model_dict.keys()}\n",
    "        \n",
    "        precision, recall, f1 = compute_precision_recall_f1(gt_topics, pred_topics)\n",
    "        \n",
    "        metrics[model][\"precision\"].append(precision)\n",
    "        metrics[model][\"recall\"].append(recall)\n",
    "        metrics[model][\"f1\"].append(f1)\n",
    "\n",
    "# Compute the average scores for each model and print them\n",
    "for model in models:\n",
    "    avg_precision = sum(metrics[model][\"precision\"]) / len(metrics[model][\"precision\"])\n",
    "    avg_recall = sum(metrics[model][\"recall\"]) / len(metrics[model][\"recall\"])\n",
    "    avg_f1 = sum(metrics[model][\"f1\"]) / len(metrics[model][\"f1\"])\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"  Precision: {avg_precision:.3f}\")\n",
    "    print(f\"  Recall:    {avg_recall:.3f}\")\n",
    "    print(f\"  F1 Score:  {avg_f1:.3f}\")\n",
    "    print(\"-\" * 30)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.178.207:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "Exception ignored in: <module 'threading' from '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py'>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1594, in _shutdown\n",
      "    atexit_call()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py\", line 31, in _python_exit\n",
      "    t.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1149, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/davide.zanutto1/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/streamlit/web/bootstrap.py\", line 44, in signal_handler\n",
      "    server.stop()\n",
      "  File \"/Users/davide.zanutto1/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/streamlit/web/server/server.py\", line 432, in stop\n",
      "    self._runtime.stop()\n",
      "  File \"/Users/davide.zanutto1/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/streamlit/runtime/runtime.py\", line 324, in stop\n",
      "    async_objs.eventloop.call_soon_threadsafe(stop_on_eventloop)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 840, in call_soon_threadsafe\n",
      "    self._check_closed()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 541, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratings-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from ../csv/train.csv\n",
      "Loading evaluation data from ../csv/test.csv\n",
      "\n",
      "TRAIN sample after parsing:\n",
      "[{'article_id': 30258060, 'review': 'Perfect for my kitchen window. Perfect for my kitchen window', 'all_topics': ['Size', 'Installation', 'Material', 'Price', 'Design', 'Magnet', 'Light', 'Quality'], 'selected_topics': ['Design']}, {'article_id': 20336087, 'review': 'I LOVE THEM. Simply I love the design. I have all the sizes.', 'all_topics': ['Size', 'Shape', 'Design', 'Quality', 'Replacement', 'Price', 'Durability', 'Functionality'], 'selected_topics': ['Design', 'Size']}]\n",
      "\n",
      "TEST sample after parsing:\n",
      "[{'article_id': 40349946, 'review': 'Good strong quality and absorbency. Good strong quality and absorbency', 'all_topics': ['Quality', 'Size', 'Appearance', 'Thickness', 'Value', 'Colors', 'Cloth-like', 'Absorbency'], 'selected_topics': ['Quality', 'Absorbency']}, {'article_id': 90610209, 'review': 'Pillow is as advertised.  Good quality.. Reasonable purchase price and fairly good quality of pillow. (Dvala)', 'all_topics': ['Quality', 'Price', 'Softness', 'Fit', 'Comfort', 'Color', 'Size', 'Value'], 'selected_topics': ['Quality', 'Price', 'Value']}]\n",
      "\n",
      "Sample NLI records:\n",
      "[{'premise': 'Perfect for my kitchen window. Perfect for my kitchen window', 'hypothesis': 'This review is about Size.', 'label': 0}, {'premise': 'Perfect for my kitchen window. Perfect for my kitchen window', 'hypothesis': 'This review is about Installation.', 'label': 0}]\n",
      "\n",
      "Sample NLI records:\n",
      "[{'premise': 'Good strong quality and absorbency. Good strong quality and absorbency', 'hypothesis': 'This review is about Quality.', 'label': 2}, {'premise': 'Good strong quality and absorbency. Good strong quality and absorbency', 'hypothesis': 'This review is about Size.', 'label': 0}]\n",
      "\n",
      "Total train NLI pairs: 78996\n",
      "Total eval  NLI pairs: 8789\n",
      "\n",
      "Tokenizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  99%|█████████▊| 78000/78996 [00:03<00:00, 24448.73 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 91\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(\n\u001b[1;32m     83\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpremise\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     84\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhypothesis\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mMAX_LEN\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTokenizing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m train_tok \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m eval_tok  \u001b[38;5;241m=\u001b[39m eval_ds\u001b[38;5;241m.\u001b[39mmap(tokenize_batch, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m (train_tok, eval_tok):\n",
      "File \u001b[0;32m~/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    555\u001b[0m }\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    558\u001b[0m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/datasets/arrow_dataset.py:3074\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3070\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3071\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3072\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3073\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3074\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3075\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3076\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/datasets/arrow_dataset.py:3531\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3529\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(batch\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[1;32m   3530\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3531\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3532\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[1;32m   3533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[0;32m~/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/datasets/arrow_writer.py:610\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    608\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m    609\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n\u001b[0;32m--> 610\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ratings-reviews-ai-summaries-topics/ratings-reviews/lib/python3.12/site-packages/datasets/arrow_writer.py:628\u001b[0m, in \u001b[0;36mArrowWriter.write_table\u001b[0;34m(self, pa_table, writer_batch_size)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[0;32m--> 628\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpa_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 0. CONFIGURE YOUR PATHS HERE\n",
    "TRAIN_CSV = \"../csv/train.csv\"\n",
    "TEST_CSV  = \"../csv/test.csv\"\n",
    "MODEL_NAME  = \"facebook/bart-large-mnli\"\n",
    "OUTPUT_DIR  = \"./bart-mnli-finetuned\"\n",
    "BATCH_SIZE  = 8\n",
    "MAX_LEN     = 128\n",
    "EPOCHS      = 3\n",
    "SEED        = 42\n",
    "\n",
    "# 1. A SIMPLE REGEX PARSER FOR \"['A', 'B', 'C']\" STRINGS\n",
    "def parse_list_field(s: str) -> list[str]:\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    # find everything between single quotes\n",
    "    return re.findall(r\"'([^']*)'\", s)\n",
    "\n",
    "# 2. LOAD AND PARSE TRAIN & TEST\n",
    "def load_and_parse(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # parse both fields\n",
    "    df[\"all_topics\"]      = df[\"all_topics\"].apply(parse_list_field)\n",
    "    df[\"selected_topics\"] = df[\"selected_topics\"].apply(parse_list_field)\n",
    "    return df\n",
    "\n",
    "print(\"Loading training data from\", TRAIN_CSV)\n",
    "train_df = load_and_parse(TRAIN_CSV)\n",
    "print(\"Loading evaluation data from\", TEST_CSV)\n",
    "eval_df  = load_and_parse(TEST_CSV)\n",
    "\n",
    "# DEBUG: print a couple of rows\n",
    "print(\"\\nTRAIN sample after parsing:\")\n",
    "print(train_df.head(2).to_dict(orient=\"records\"))\n",
    "print(\"\\nTEST sample after parsing:\")\n",
    "print(eval_df.head(2).to_dict(orient=\"records\"))\n",
    "\n",
    "# 3. BUILD NLI EXAMPLES\n",
    "def make_nli_records(df: pd.DataFrame):\n",
    "    records = []\n",
    "    for _, row in df.iterrows():\n",
    "        premise = row[\"review\"]\n",
    "        for topic in row[\"all_topics\"]:\n",
    "            # 2 = entailment, 0 = contradiction\n",
    "            label = 2 if topic in row[\"selected_topics\"] else 0\n",
    "            records.append({\n",
    "                \"premise\": premise,\n",
    "                \"hypothesis\": f\"This review is about {topic}.\",\n",
    "                \"label\": label\n",
    "            })\n",
    "    return records\n",
    "\n",
    "train_records = make_nli_records(train_df)\n",
    "eval_records  = make_nli_records(eval_df)\n",
    "print(\"\\nSample NLI records:\")\n",
    "print(train_records[:2])\n",
    "print(\"\\nSample NLI records:\") \n",
    "print(eval_records[:2])\n",
    "print(f\"\\nTotal train NLI pairs: {len(train_records)}\")\n",
    "print(f\"Total eval  NLI pairs: {len(eval_records)}\")\n",
    "\n",
    "# 4. CONVERT TO HUGGINGFACE DATASETS\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame(train_records))\n",
    "eval_ds  = Dataset.from_pandas(pd.DataFrame(eval_records))\n",
    "\n",
    "# 5. TOKENIZE\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"premise\"],\n",
    "        batch[\"hypothesis\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LEN\n",
    "    )\n",
    "\n",
    "print(\"\\nTokenizing...\")\n",
    "train_tok = train_ds.map(tokenize_batch, batched=True)\n",
    "eval_tok  = eval_ds.map(tokenize_batch, batched=True)\n",
    "\n",
    "for ds in (train_tok, eval_tok):\n",
    "    ds = ds.remove_columns([\"premise\",\"hypothesis\"])\n",
    "    ds = ds.rename_column(\"label\",\"labels\")\n",
    "    ds.set_format(\"torch\")\n",
    "\n",
    "# 6. LOAD MODEL\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# 7. METRICS\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
    "\n",
    "# 8. TRAINING ARGUMENTS\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "# 9. TRAINER SETUP\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=eval_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 10. TRAIN & SAVE\n",
    "print(\"\\nStarting fine‑tuning...\")\n",
    "trainer.train()\n",
    "print(\"Saving model to\", OUTPUT_DIR)\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratings-reviews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
